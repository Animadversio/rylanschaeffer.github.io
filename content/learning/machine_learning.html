<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <meta name="description" content="Rylan Schaeffer">

    <link rel="stylesheet" type="text/css" media="all" href="../../stylesheets/stylesheet.css">

    <title></title>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-94033137-1', 'auto');
      ga('send', 'pageview');
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

    <script type="text/javascript"
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
    </script>

    $\DeclareMathOperator*{\argmax}{argmax}$
    $\DeclareMathOperator{\defeq}{\stackrel{def}{=}}$
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
      <header class="inner">
        <h1 id="header_title">Rylan Schaeffer > Learning > Machine Learning</h1>
        <nav>
          <div>
            <a href="../learning.html">Learning</a>
          </div>
        </nav>
      </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">

        <div id="toc_container">
          <h1 class="toc_title">Contents</h1>
          <ul class="table-of-content" id="markdown-toc">
            <li id="#objective_functions">Objective Functions <ul>
              <li><a href="#mean_squared_error">Mean Squared Error</a><ul>
                <li><a href="#unpacking_supervised_mse">Unpacking MSE in Supervised Learning</a> </li>
              </ul></li>
            </li>
            </ul></li>
            <li>Bias - Variance Trade-Off </li>
          </ul>
        </div>

        <h1 id="objective_functions">Objective Functions</h1>

        <h2 id="mean_squared_error">Mean Squared Error</h2>
          <h3 id="unpacking_supervised_mse">Unpacked MSE in Supervised Learning</h3>
            <p>
              Suppose we'd like to better understand our expected loss when
              performing regression over a supervised dataset $\{(x_i, y_i )\}_{i=1}^N$.
              Under the MSE objective function, our expected loss is equal to

              $
              \begin{align}
              \mathbb{E}[L] = \int_\mathbb{X} \int_\mathbb{Y} L(f(x), y) p(x, y) dy dx
              = \int_\mathbb{X} \int_\mathbb{Y} (f(x) - y)^2 p(x, y) dy dx
              \end{align}
              $
            </p>

            <p>
              If the true expected value of $y$ conditioned on $x$ is
              $\mathbb{E}[y|x] \defeq \int_\mathbb{Y} y p(y|x) dy$, then we can
              decompose the expected loss into two meaningful terms:

              $
              \begin{align}
              \mathbb{E}[L] &= \int_\mathbb{X} \int_\mathbb{Y} (f(x) - y)^2 p(x, y) dy dx \nonumber \\
              &= \int_\mathbb{X} \int_\mathbb{Y} (f(x) - \mathbb{E}[y|x] + \mathbb{E}[y|x] - y)^2 p(x, y) dy dx \nonumber \\
              &= \int_\mathbb{X} \int_\mathbb{Y} (f(x) - \mathbb{E}[y|x])^2 p(x,y) dy dx +
                  2 \int_\mathbb{X} \int_\mathbb{Y} (f(x) - \mathbb{E}[y|x])(\mathbb{E}[y|x] - y) p(x, y) dy dx +
                  \int_\mathbb{X} \int_\mathbb{Y} (\mathbb{E}[y|x] - y)^2 p(x, y) dy dx \nonumber
              \end{align}
              $
            </p>

            <p>
              The middle term will vanish, since $\int_\mathbb{Y} y p(x, y) dy =
              p(x) \int_\mathbb{Y} y p(x|y) dy = p(x) \mathbb{E}[y|x]$:
            </p>

            <p>
              $
              \begin{align}
              \text{middle term} &= \int_\mathbb{X} \int_\mathbb{Y} (f(x) - \mathbb{E}[y|x])(\mathbb{E}[y|x] - y) p(x, y) dy dx \nonumber \\
              &= \int_\mathbb{X} f(x) \mathbb{E}[y|x] \int_\mathbb{Y} p(x,y) dy dx -
              \int_\mathbb{X} f(x)  \int_\mathbb{Y} y p(x,y) dy dx -
              \int_\mathbb{X} \mathbb{E}[y|x] ^ 2 \int_\mathbb{Y} p(x,y) dy dx +
              \int_\mathbb{X} \mathbb{E}[y|x] \int_\mathbb{Y} y p(x,y) dy dx \nonumber \\
              &= \int_\mathbb{X} f(x) \mathbb{E}[y|x] p(x) dx -
                  \int_\mathbb{X} f(x) \mathbb{E}[y|x] p(x) dx -
                  \int_\mathbb{X} \mathbb{E}[y|x] ^ 2 p(x) dx +
                  \int_\mathbb{X} \mathbb{E}[y|x] ^ 2 p(x) dx \nonumber \\
              &= 0 \nonumber
              \end{align}
              $
            </p>

            <p>
              We can also simplify the last term $\int_\mathbb{X} \int_\mathbb{Y} (\mathbb{E}[y|x] - y) p(x, y) dy dx$
              by remembering that for random variable $a$, $\mathbb{E}[a^2] \defeq
              \mathbb{E}[a]^2 + \mathbb{V}[a]$:
            </p>

            <p>
              $
              \begin{align}
              \text{last term} &= \int_\mathbb{X} \int_\mathbb{Y} (\mathbb{E}[y|x] - y)^2 p(x, y) dy dx \nonumber \\
              &= \int_\mathbb{X} \mathbb{E}[y|x]^2 p(x) dx -
                  2 \int_\mathbb{X} \mathbb{E}[y|x]^2 p(x) dx +
                  \int_\mathbb{X} \mathbb{E}[y^2|x] p(x) dx \nonumber \\
              &= \int_\mathbb{X} \mathbb{E}[y|x]^2 p(x) dx -
              2 \int_\mathbb{X} \mathbb{E}[y|x]^2 p(x) dx +
              \int_\mathbb{X} (\mathbb{E}[y|x]^2 + \mathbb{V}[y|x]) p(x) dx\nonumber \\
              &= \int_\mathbb{X} \mathbb{V}[y|x]) p(x) dx \nonumber \\
              &= \int_\mathbb{X} (\mathbb{E}[y|x] - y)^2 p(x) dx \nonumber
              \end{align}
              $
            </p>

            <p>
              Putting everything together, we see that
              $
              \begin{align}
              \mathbb{E}[L] = \int_\mathbb{X} (f(x) - \mathbb{E}[y|x])^2 p(x) dx +
              \int_\mathbb{X} (\mathbb{E}[y|x] - y)^2 p(x) dx
              \end{align}
              $
            </p>

            <p>
              The significance of this result is twofold. First, the expected loss
              is the sum of two distinct losses: how far our model $f(x)$ differs from
              the true conditional expected value $\mathbb{E}[y|x]$, and how the
              variance inherent in the data. Second, it tells us that the optimal
              model (i.e. the model that minimizes the expected loss under MSE) is
              the model that matches the conditional expected value.
            </p>
      </section>
    </div>

    <!--FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <h3 id="footer_title">Rylan Schaeffer</h3>
        <p>
          I appreciate any and all feedback. If I've made an error or if you have a suggestion, please
          email me at <a href="mailto:rylanschaeffer@gmail.com">rylanschaeffer@gmail.com</a>.
        </p>
      </footer>
    </div>

    
  </body>
</html>
